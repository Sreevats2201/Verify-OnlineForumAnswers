{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the data into a pandas dataframe\n",
    "def data2df (path, label):\n",
    "    file, text = [], []\n",
    "    for f in os.listdir(path):\n",
    "        file.append(f)\n",
    "        fhr = open(path+f, 'r', encoding='utf-8', errors='ignore') \n",
    "        t = fhr.read()\n",
    "        text.append(t)\n",
    "        fhr.close()\n",
    "    return(pd.DataFrame({'file': file, 'text': text, 'class':label}))\n",
    "\n",
    "dfpro = data2df('HealthProNonPro/HealthProNonPro/Pro/', 0) # Pro\n",
    "dfnonpro = data2df('HealthProNonPro/HealthProNonPro/NonPro/', 1) # NonPro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pro - Professional answers by verified doctors\n",
    "\n",
    "NonPro - Answers by other members of the community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>825</td>\n",
       "      <td>ans1741.txt</td>\n",
       "      <td>White patches on the skin could be caused by a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1430</td>\n",
       "      <td>ans6.txt</td>\n",
       "      <td>A cat scratch could lead to local infection by...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1496</td>\n",
       "      <td>a69631.txt</td>\n",
       "      <td>Its called procrastination.  You have to break...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1741</td>\n",
       "      <td>ans88.txt</td>\n",
       "      <td>Although eating raw rice may not necessarily c...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1364</td>\n",
       "      <td>a69497.txt</td>\n",
       "      <td>is your name mary if not then no hehehehe derr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>947</td>\n",
       "      <td>ans1851.txt</td>\n",
       "      <td>Your symptoms of abdominal cramps could be cau...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1747</td>\n",
       "      <td>ans885.txt</td>\n",
       "      <td>Most cases of breast tenderness is usually rel...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1598</td>\n",
       "      <td>a7386.txt</td>\n",
       "      <td>I do</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>899</td>\n",
       "      <td>a54305.txt</td>\n",
       "      <td>Plenty of fluids and rest.   OJ, Water, Soups,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1296</td>\n",
       "      <td>a69428.txt</td>\n",
       "      <td>I know people who have athritis and it is supp...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1453</td>\n",
       "      <td>a69588.txt</td>\n",
       "      <td>Your eggs are in your uterus. Not in your stom...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>606</td>\n",
       "      <td>ans1544.txt</td>\n",
       "      <td>There are many conditions that may lead to the...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>307</td>\n",
       "      <td>ans1275.txt</td>\n",
       "      <td>Thank you for your question. We are not aware ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>213</td>\n",
       "      <td>a24445.txt</td>\n",
       "      <td>Learn to take a 5 minute stretching break.  So...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>191</td>\n",
       "      <td>a24423.txt</td>\n",
       "      <td>Try to sleep more than six hours, before going...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1622</td>\n",
       "      <td>ans772.txt</td>\n",
       "      <td>It is understandable to be concerned about pre...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1543</td>\n",
       "      <td>ans700.txt</td>\n",
       "      <td>It is difficult for me to say whether you are ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>654</td>\n",
       "      <td>ans1588.txt</td>\n",
       "      <td>There is nothing you can do to shorten the dur...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             file                                               text  class\n",
       "825   ans1741.txt  White patches on the skin could be caused by a...      0\n",
       "1430     ans6.txt  A cat scratch could lead to local infection by...      0\n",
       "1496   a69631.txt  Its called procrastination.  You have to break...      1\n",
       "1741    ans88.txt  Although eating raw rice may not necessarily c...      0\n",
       "1364   a69497.txt  is your name mary if not then no hehehehe derr...      1\n",
       "947   ans1851.txt  Your symptoms of abdominal cramps could be cau...      0\n",
       "1747   ans885.txt  Most cases of breast tenderness is usually rel...      0\n",
       "1598    a7386.txt                                              I do       1\n",
       "899    a54305.txt  Plenty of fluids and rest.   OJ, Water, Soups,...      1\n",
       "1296   a69428.txt  I know people who have athritis and it is supp...      1\n",
       "1453   a69588.txt  Your eggs are in your uterus. Not in your stom...      1\n",
       "606   ans1544.txt  There are many conditions that may lead to the...      0\n",
       "307   ans1275.txt  Thank you for your question. We are not aware ...      0\n",
       "213    a24445.txt  Learn to take a 5 minute stretching break.  So...      1\n",
       "191    a24423.txt  Try to sleep more than six hours, before going...      1\n",
       "1622   ans772.txt  It is understandable to be concerned about pre...      0\n",
       "1543   ans700.txt  It is difficult for me to say whether you are ...      0\n",
       "654   ans1588.txt  There is nothing you can do to shorten the dur...      0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([dfpro, dfnonpro], axis=0)\n",
    "df.sample(frac=0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1874\n",
       "1    1787\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['class'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we have here is a pretty balanced dataset so hopefully we should be getting good results without complicating our model too much"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's divide our data into 2 parts - Train and Validation sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "439     The most common cause of itchy palms is contac...\n",
       "720     1. It takes two to make the money to support t...\n",
       "307     there isnt always signs\\nso do not do it until...\n",
       "87      Speed is an amphetamine, a psychostimulant, wh...\n",
       "1066                                         tantric sex \n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df['text']\n",
    "y = df['class']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=1)\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Tokenizer Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A custom tokenizer function - This is where we set in the rules for which we consider words into the corpus.\n",
    "\n",
    "**Note** : Documentation  is included for the other arguments you can give for this function. This combination seems to work best and it makes intuitive sense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_tokenizer(doc):\n",
    "\n",
    "    # clean up text\n",
    "    tokens = [token.lemma_.lower() # lemmatize and lower-case \n",
    "                        for token in doc \n",
    "                               if (\n",
    "                                    len(token) >= 2 and # only preserve tokens that are 2 or more characters long\n",
    "                                    #token.pos_ in ['PROPN', 'NOUN', 'ADJ', 'VERB', 'ADV'] and # only preserve specific pos\n",
    "                                    #token.text in nlp.vocab and # check if token in vocab\n",
    "                                    token.is_alpha and # only preserve tokens that are fully alpha (not numeric or alpha-numeric)\n",
    "                                    #not token.is_digit and # get rid of tokens that are fully numeric\n",
    "                                    not token.is_punct and # get rid of tokens that are punctuations\n",
    "                                    not token.is_space and # get rid of tokens that are spaces\n",
    "                                    not token.is_stop # get rid of tokens that are stop words\n",
    "                                )\n",
    "                   ]\n",
    "\n",
    "    # return cleaned-up text\n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing using SpacY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using SpacY's medium size dictionary and with the help of our custom tokenizer, we extract the words after stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_md\", disable=['parser', 'ner'])\n",
    "nlpcorpus = nlp.pipe(X_train)\n",
    "clean_corpus = [custom_tokenizer(doc) for doc in nlpcorpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['depend variable time month correlation girl period cycle condition male female etc healthy adult depend duration frequency time thing odd low',\n",
       " 'answer list thread complete answer provide source section link website deal bipolar disorder diease formally know manic depressive disorder bipolar people exhibit sign manic depressiviness disorder eventually seperate distinct bipolar simply form depressive state person dramatic mood swing long short period time people suffer bipolar disorder fine week month sudden turn major depressive state self destructive suicidal nature week month road fine bipolar disorder chemeical imbalance brain seritonin chemical inihibit natural ability control impulse deprssive states condition respond medication therapy not worried fine job supportive friend matter website information bipolar disorder',\n",
       " 'think depressed need nature way tell need not kinda odd not think depress choice say have world will not bad mistake away take throw people include little thing sound like choice get skin little bit throw possible need correct choice maybe thing lifestyle different stroke different folk eh',\n",
       " 'take stress management class work madatory important thing instructor say deep breathing breath chest move breathe correctly stomach go breath diaphragm nose mouth say meditate find distraction quiet will not interrupt soothing music picture beach picture beach sand sound ocean concentrate thing breathe deeply say not worry thing control not let people skin exercise people feel good not seriously hopefully help',\n",
       " 'build clear mental image dark room candle stick single tall white candle light flame straight sure concentrate image minute half hour ready take']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "random.sample(clean_corpus,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above we can see a random sample of 5 answers after our processing on it. It seems to be good but let's see how it performs on our model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "439     common cause itchy palm contact dermatitis exp...\n",
       "720     take money support famlys need like food shelt...\n",
       "307                      not sign married doctor approval\n",
       "87      speed amphetamine psychostimulant commonly abu...\n",
       "1066                                          tantric sex\n",
       "                              ...                        \n",
       "889                  week body makeover need info mail ok\n",
       "905     father factor produce symptom generally patien...\n",
       "1096    fiberoptic endoscopy upper gi tract investigat...\n",
       "235     atopic dermatitis eczema chronic inflammatory ...\n",
       "1061    endoscopic sinus surgery procedure choice remo...\n",
       "Length: 2928, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = pd.Series(clean_corpus,index=X_train.index)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use a pipeline here. Steps\n",
    "1. First step is to create a TF_IDF matrix \n",
    "2. Second, we feed this data to a Multinomial Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = Pipeline(steps=[('tf',TfidfVectorizer()),\\\n",
    "                      ('nbc',MultinomialNB())])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grid Search to perform hyper-parameter optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {'tf__sublinear_tf' : [True,False], 'tf__smooth_idf' : [True,False], 'tf__norm' : ['l1','l2'],\\\n",
    "              'nbc__alpha' : [1.0,1.2,1.4,1.6]}\n",
    "gscv = GridSearchCV(clf,param_grid,cv=4,return_train_score=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('tf',\n",
       "                 TfidfVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.float64'>,\n",
       "                                 encoding='utf-8', input='content',\n",
       "                                 lowercase=True, max_df=1.0, max_features=None,\n",
       "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
       "                                 preprocessor=None, smooth_idf=True,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 sublinear_tf=False,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, use_idf=True,\n",
       "                                 vocabulary=None)),\n",
       "                ('nbc',\n",
       "                 MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gscv.fit(X_train,y_train)\n",
    "\n",
    "gscv.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our best training accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9262295081967213"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gscv.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best set of training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'nbc__alpha': 1.0,\n",
       " 'tf__norm': 'l2',\n",
       " 'tf__smooth_idf': True,\n",
       " 'tf__sublinear_tf': False}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gscv.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's use the best estimator model of the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = gscv.best_estimator_.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9167803547066848"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "metrics.accuracy_score(y_test,preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get an accuracy of 92% , which is really good. But then again our dataset was well balanced too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[341,  34],\n",
       "       [ 27, 331]], dtype=int64)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.confusion_matrix(y_test,preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.91      0.92       375\n",
      "           1       0.91      0.92      0.92       358\n",
      "\n",
      "    accuracy                           0.92       733\n",
      "   macro avg       0.92      0.92      0.92       733\n",
      "weighted avg       0.92      0.92      0.92       733\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test,preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our classification report and confusion matrix also indicate that we have good precision, recall and f-1 scores as well."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
